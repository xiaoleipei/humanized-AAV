{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HOk4iZ9YZvec"
   },
   "outputs": [],
   "source": [
    "# in this notebook we'll only get one of the files (the Oscar one) for the sake of simplicity and performance\n",
    "!wget -c https://cdn-datasets.huggingface.co/EsperBERTo/data/oscar.eo.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-kkz81OY6xH"
   },
   "source": [
    "## 2. Train a tokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5duRggBRZKvP"
   },
   "outputs": [],
   "source": [
    "# We won't need TensorFlow here\n",
    "!pip uninstall -y tensorflow\n",
    "# Install `transformers` from master\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip list | grep -E 'transformers|tokenizers'\n",
    "# transformers version at notebook update --- 2.11.0\n",
    "# tokenizers version at notebook update --- 0.8.0rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "aav2= pd.read_csv(\"../huggingface/human_virus2.csv\")\n",
    "\n",
    "\n",
    "aav2[\"sequence\"]=aav2[\"sequence\"].str.upper()\n",
    "\n",
    "aav_data=[]\n",
    "for line in aav2[\"sequence\"]:\n",
    "    line2=line.replace(\"\",\" \")\n",
    "    aav_data.append(line2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"humanized_data.csv\", \"w\", newline='') as csvfile:\n",
    "    for i in aav_data:\n",
    "        csvfile.write(i)\n",
    "\n",
    "        #csvfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "IMnymRDLe0hi",
    "outputId": "4d26476f-e6b5-475a-a0c1-41b6fcdc041a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from pathlib import Path\n",
    "\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "paths = [str(x) for x in Path(\"../huggingface/\").glob(\"humanized_data.csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "IMnymRDLe0hi",
    "outputId": "4d26476f-e6b5-475a-a0c1-41b6fcdc041a"
   },
   "outputs": [],
   "source": [
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "IMnymRDLe0hi",
    "outputId": "4d26476f-e6b5-475a-a0c1-41b6fcdc041a"
   },
   "outputs": [],
   "source": [
    "# Customize training\n",
    "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(vocabulary_size=281, model=ByteLevelBPE, add_prefix_space=False, lowercase=False, dropout=None, unicode_normalizer=None, continuing_subword_prefix=None, end_of_word_suffix=None, trim_offsets=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ei7bqpRf1LH"
   },
   "source": [
    "Now let's save files to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "EIS-irI0f32P",
    "outputId": "e86c4a24-eb65-4f0a-aa58-ed1931a05ac9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Â≠êÁõÆÂΩïÊàñÊñá‰ª∂ EsperBERTo Â∑≤ÁªèÂ≠òÂú®„ÄÇ\n"
     ]
    }
   ],
   "source": [
    "!mkdir EsperBERTo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "EIS-irI0f32P",
    "outputId": "e86c4a24-eb65-4f0a-aa58-ed1931a05ac9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../huggingface/models/humanzied_bert\\\\vocab.json',\n",
       " '../huggingface/models/humanzied_bert\\\\merges.txt']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_model(\"../huggingface/models/humanzied_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tKVWB8WShT-z"
   },
   "outputs": [],
   "source": [
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tKVWB8WShT-z"
   },
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"../huggingface/models/aav2bert/vocab.json\",\n",
    "    \"../huggingface/models/aav2bert/merges.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hO5M3vrAhcuj"
   },
   "outputs": [],
   "source": [
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")\n",
    "tokenizer.enable_truncation(max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "E3Ye27nchfzq",
    "outputId": "b9812ed2-1ecd-4e1b-d9bd-7de581955e70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=21, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"DGYLPDWLEDNLSEGIREW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQpUC_CDhnWW"
   },
   "source": [
    "## 3. Train a language model from scratch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "kD140sFjh0LQ",
    "outputId": "0bab1f9e-bf7a-4f13-82d3-07fe5866ce78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 27 12:51:22 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.94       Driver Version: 516.94       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:03:00.0  On |                  N/A |\n",
      "|  0%   35C    P8     7W / 170W |    540MiB / 12288MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      4392    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      5096    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A      6120    C+G   ...e\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      6768    C+G   ...ysdiag\\bin\\HipsDaemon.exe    N/A      |\n",
      "|    0   N/A  N/A      9252    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     10372    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     11276    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     12888    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     14136    C+G   C:\\Windows\\System32\\dwm.exe     N/A      |\n",
      "|    0   N/A  N/A     14220    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     14724    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15152    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check that we have a GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "VNZZs-r6iKAV",
    "outputId": "c8404d6c-7662-4240-c8da-ee89edfaf51b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\racoon\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that PyTorch sees it\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0qQzgrBi1OX"
   },
   "source": [
    "### We'll define the following config for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LTXXutqeDzPi"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=52_000,\n",
    "    max_position_embeddings=514,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAwQ82JiE5pi"
   },
   "source": [
    "Now let's re-create our tokenizer in transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4keFBUjQFOD1"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"../huggingface/models/aav2bert\", max_len=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yNCw-3hFv9h"
   },
   "source": [
    "Finally let's initialize our model.\n",
    "\n",
    "**Important:**\n",
    "\n",
    "As we are training from scratch, we only initialize from a config, not from an existing pretrained model or checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BzMqR-dzF4Ro"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "model = RobertaForMaskedLM(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "jU6JhBSTKiaM",
    "outputId": "35879a60-2915-4894-f702-2d649cfa398a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83504416"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()\n",
    "# => 84 million parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBtUHRMliOLM"
   },
   "source": [
    "### Now let's build our training Dataset\n",
    "\n",
    "We'll build our dataset by applying our tokenizer to our text file.\n",
    "\n",
    "Here, as we only have one text file, we don't even need to customize our `Dataset`. We'll just use the `LineByLineDataset` out-of-the-box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "GlvP_A-THEEl",
    "outputId": "e0510a33-7937-4a04-fa1c-d4e20b758bb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\racoon\\anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import LineByLineTextDataset\n",
    "\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"D:/jupyter_notebook/huggingface/data/humanized_data.csv\",\n",
    "    block_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.data.datasets.language_modeling.LineByLineTextDataset at 0x17687b99708>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDLs73HcIHk5"
   },
   "source": [
    "Like in the [`run_language_modeling.py`](https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_language_modeling.py) script, we need to define a data_collator.\n",
    "\n",
    "This is just a small helper that will help us batch different samples of the dataset together into an object that PyTorch knows how to perform backprop on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zTgWPa9Dipk2"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri2BIQKqjfHm"
   },
   "source": [
    "### Finally, we are all set to initialize our Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YpvnFFmZJD-N"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"D:/jupyter_notebook/huggingface/models/humanized_bert\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    per_gpu_train_batch_size=128,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6sASa36Nf-N"
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738,
     "referenced_widgets": [
      "a58a66392b644b1384661e850c077a6c",
      "a491e8caa0a048beb3b5259f14eb233f",
      "837c9ddc3d594e088891874560c646b8",
      "dbf50873d62c4ba39321faefbed0cca5",
      "40bf955ba0284e84b198da6be8654219",
      "fe20a8dae6e84628b5076d02183090f5",
      "93b3f9eae3cb4e3e859cf456e3547c6d",
      "6feb10aeb43147e6aba028d065947ae8",
      "0989d41a4da24e9ebff377e02127642c",
      "42c6061ef7e44f179db5a6e3551c0f17",
      "d295dd80550447d88da0f04ce36a22ff",
      "04e7e6d291da49d5816dc98a2904e95c",
      "e7d8c3a4fecd40778e32966b29ea65a1",
      "016d7c8318f742c1943464b08232a510",
      "8388e9da9da4492c98c19235ca5fc1b5",
      "39c23c6a972b419eb2eeeebafeaedc22"
     ]
    },
    "id": "VmaHZXzmkNtJ",
    "outputId": "a19880cb-bcc6-4885-bf24-c2c6d0f56d1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "C:\\Users\\racoon\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.08 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=9.237300872802734, metrics={'train_runtime': 7.0424, 'train_samples_per_second': 1.42, 'train_steps_per_second': 1.42, 'total_flos': 331567841280.0, 'train_loss': 9.237300872802734, 'epoch': 10.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZkooHz1-_2h"
   },
   "source": [
    "#### üéâ Save final model (+ tokenizer + config) to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "QDNgPls7_l13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to D:/jupyter_notebook/huggingface/models/humanized_bert\n",
      "Configuration saved in D:/jupyter_notebook/huggingface/models/humanized_bert\\config.json\n",
      "Model weights saved in D:/jupyter_notebook/huggingface/models/humanized_bert\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"D:/jupyter_notebook/huggingface/models/humanized_bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0caceCy_p1-"
   },
   "source": [
    "## 4. Check that the LM actually trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIQJ8ND_AEhl"
   },
   "source": [
    "Aside from looking at the training and eval losses going down, the easiest way to check whether our language model is learning anything interesting is via the `FillMaskPipeline`.\n",
    "\n",
    "Pipelines are simple wrappers around tokenizers and models, and the 'fill-mask' one will let you input a sequence containing a masked token (here, `<mask>`) and return a list of the most probable filled sequences, with their probabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ltXgXyCbAJLY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file D:/jupyter_notebook/huggingface/models/humanized_bert\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"D:/jupyter_notebook/huggingface/models/humanized_bert\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "loading configuration file D:/jupyter_notebook/huggingface/models/humanized_bert\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"D:/jupyter_notebook/huggingface/models/humanized_bert\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "loading weights file D:/jupyter_notebook/huggingface/models/humanized_bert\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForMaskedLM.\n",
      "\n",
      "All the weights of RobertaForMaskedLM were initialized from the model checkpoint at D:/jupyter_notebook/huggingface/models/humanized_bert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n",
      "loading configuration file ../huggingface/models/aav2bert\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"../huggingface/models/aav2bert\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "Didn't find file ../huggingface/models/aav2bert\\tokenizer.json. We won't load it.\n",
      "Didn't find file ../huggingface/models/aav2bert\\added_tokens.json. We won't load it.\n",
      "Didn't find file ../huggingface/models/aav2bert\\special_tokens_map.json. We won't load it.\n",
      "Didn't find file ../huggingface/models/aav2bert\\tokenizer_config.json. We won't load it.\n",
      "loading file ../huggingface/models/aav2bert\\vocab.json\n",
      "loading file ../huggingface/models/aav2bert\\merges.txt\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading configuration file ../huggingface/models/aav2bert\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"../huggingface/models/aav2bert\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "loading configuration file ../huggingface/models/aav2bert\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"../huggingface/models/aav2bert\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"D:/jupyter_notebook/huggingface/models/humanized_bert\",\n",
    "    tokenizer=\"../huggingface/models/aav2bert\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "UIvgZ3S6AO0z",
    "outputId": "5f3d2f00-abdc-44a9-9c1b-75e3ec328576",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.0011512604542076588,\n",
       "   'token': 265,\n",
       "   'token_str': ' L',\n",
       "   'sequence': '<s> I R E W W L<mask> P G A P K P K </s>'},\n",
       "  {'score': 0.0009419691050425172,\n",
       "   'token': 268,\n",
       "   'token_str': ' D',\n",
       "   'sequence': '<s> I R E W W D<mask> P G A P K P K </s>'},\n",
       "  {'score': 0.0005524407024495304,\n",
       "   'token': 262,\n",
       "   'token_str': ' S',\n",
       "   'sequence': '<s> I R E W W S<mask> P G A P K P K </s>'},\n",
       "  {'score': 0.0004307684430386871,\n",
       "   'token': 267,\n",
       "   'token_str': ' A',\n",
       "   'sequence': '<s> I R E W W A<mask> P G A P K P K </s>'},\n",
       "  {'score': 0.0002452126645948738,\n",
       "   'token': 261,\n",
       "   'token_str': ' G',\n",
       "   'sequence': '<s> I R E W W G<mask> P G A P K P K </s>'}],\n",
       " [{'score': 0.0012744325213134289,\n",
       "   'token': 265,\n",
       "   'token_str': ' L',\n",
       "   'sequence': '<s> I R E W W<mask> L P G A P K P K </s>'},\n",
       "  {'score': 0.0008551882929168642,\n",
       "   'token': 268,\n",
       "   'token_str': ' D',\n",
       "   'sequence': '<s> I R E W W<mask> D P G A P K P K </s>'},\n",
       "  {'score': 0.0005561081343330443,\n",
       "   'token': 262,\n",
       "   'token_str': ' S',\n",
       "   'sequence': '<s> I R E W W<mask> S P G A P K P K </s>'},\n",
       "  {'score': 0.00048135939869098365,\n",
       "   'token': 267,\n",
       "   'token_str': ' A',\n",
       "   'sequence': '<s> I R E W W<mask> A P G A P K P K </s>'},\n",
       "  {'score': 0.0003318885574117303,\n",
       "   'token': 275,\n",
       "   'token_str': ' K',\n",
       "   'sequence': '<s> I R E W W<mask> K P G A P K P K </s>'}]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The sun <mask>.\n",
    "# =>\n",
    "\n",
    "fill_mask(\" I R E W W <mask> <mask> P G A P K P K \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0qCyyhNAWZi"
   },
   "source": [
    "Ok, simple syntax/grammar works. Let‚Äôs try a slightly more interesting prompt:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "YZ9HSQxAAbme",
    "outputId": "aabfeedc-b1d0-4837-b01d-cd42726a5a3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.04868708550930023,\n",
       "  'token': 1283,\n",
       "  'token_str': ' tago',\n",
       "  'sequence': 'Jen la komenco de bela tago.'},\n",
       " {'score': 0.01708998531103134,\n",
       "  'token': 833,\n",
       "  'token_str': ' tempo',\n",
       "  'sequence': 'Jen la komenco de bela tempo.'},\n",
       " {'score': 0.01368900015950203,\n",
       "  'token': 1398,\n",
       "  'token_str': ' loko',\n",
       "  'sequence': 'Jen la komenco de bela loko.'},\n",
       " {'score': 0.012574958615005016,\n",
       "  'token': 966,\n",
       "  'token_str': ' vivo',\n",
       "  'sequence': 'Jen la komenco de bela vivo.'},\n",
       " {'score': 0.011642387136816978,\n",
       "  'token': 1589,\n",
       "  'token_str': ' urbo',\n",
       "  'sequence': 'Jen la komenco de bela urbo.'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask(\"Jen la komenco de bela <mask>.\")\n",
    "\n",
    "# This is the beginning of a beautiful <mask>.\n",
    "# =>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RsGaD1qAfLP"
   },
   "source": [
    "## 5. Share your model üéâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning our pretaining model of aav2bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refer https://github.com/huggingface/notebooks/blob/master/examples/text_classification.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.16.0.dev0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pylab as plt \n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ddb36989d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 123\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 1e-2\n",
    "epsilon = 1e-8\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aav2= pd.read_csv(\"../huggingface/data/human_virus_train.csv\")\n",
    "\n",
    "aav2[\"sequence\"]=aav2[\"sequence\"].str.upper()\n",
    "\n",
    "aav_data=[]\n",
    "for line in aav2[\"sequence\"]:\n",
    "    line=str(line)\n",
    "    line2=line.replace(\"\",\" \")\n",
    "    aav_data.append(line2)\n",
    "    \n",
    "    \n",
    "\n",
    "aav_data= pd.DataFrame(aav_data, columns=['sequence'])\n",
    "\n",
    "aav2_data2 = pd.concat([aav2, aav_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aav2_data2.to_csv(\"../huggingface/data/humanized_data_flow.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aav2= pd.read_csv(\"../huggingface/data/aav2_data_flew_30825_unique_seq2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aav2=aav2.sample(n=20000,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####ÔºàoptionalÔºâ\n",
    "df = aav2\n",
    "\n",
    "df = pd.DataFrame(df,columns=['mutant_21aa_text', 'antibody_escape_label'])\n",
    "\n",
    "df.columns=['sentence', 'label']\n",
    "\n",
    "df_total=df.sample(len(df))\n",
    "\n",
    "df=df_total[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##sample reduction ÔºàoptionalÔºâ\n",
    "\n",
    "df_sample_0 = df.loc[df.label == 0].sample(n=len(df.loc[df.label == 1]))\n",
    "df_1 = df.loc[df.label == 1]\n",
    "df = df_1.append(df_sample_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aav2=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = aav2[\"sentence\"]\n",
    "\n",
    "# set label\n",
    "targets = aav2[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=targets.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_targets = torch.tensor(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../huggingface/models/aav2bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25000, 52])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\racoon\\AppData\\Local\\Temp/ipykernel_18308/1587867109.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  input_tokens = torch.tensor(input_ids)\n"
     ]
    }
   ],
   "source": [
    "# embedding the protein\n",
    "def convert_text_to_token(tokenizer, sentence, limit_size = 50):\n",
    "    tokens = tokenizer.encode(sentence[:limit_size])       # cutoff\n",
    "    if len(tokens) < limit_size + 2:                       #\n",
    "        alist=list(tokens)\n",
    "        alist.extend([0] * (limit_size + 2 - len(tokens)))\n",
    "        tokens=np.array(alist)\n",
    "    return tokens\n",
    "\n",
    "input_ids = [convert_text_to_token(tokenizer, sen) for sen in sentences]\n",
    "\n",
    "input_tokens = torch.tensor(input_ids)\n",
    "print(input_tokens.shape)              # torch.Size([10000, 128])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25000, 52])\n"
     ]
    }
   ],
   "source": [
    "# build mask\n",
    "def attention_masks(input_ids):\n",
    "    atten_masks = []\n",
    "    for seq in input_ids:                       # [36269, 22]\n",
    "        seq_mask = [float(i > 0) for i in seq]  # PAD: 0; or: 1\n",
    "        atten_masks.append(seq_mask)\n",
    "    return atten_masks\n",
    "\n",
    "atten_masks = attention_masks(input_ids)\n",
    "attention_tokens = torch.tensor(atten_masks)\n",
    "print(attention_tokens.shape)                   # torch.Size([36269, 22])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 52]) torch.Size([5000, 52])\n",
      "torch.Size([20000, 52])\n",
      "tensor([  0, 280, 275, 265, 275, 263, 261, 263, 263, 263, 263, 274, 267, 274,\n",
      "        271, 279, 275, 268, 268, 262, 271, 261, 225,   2,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=torch.int32)\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(input_tokens, total_targets, \n",
    "                                                                        random_state=1, test_size=0.2)\n",
    "train_masks, test_masks, _, _ = train_test_split(attention_tokens, input_tokens, \n",
    "                                                 random_state=1, test_size=0.2)\n",
    "print(train_inputs.shape, test_inputs.shape)      #  torch.Size([2000, 128])\n",
    "print(train_masks.shape)                          # torch.Size([8000, 128])\n",
    "\n",
    "print(train_inputs[0])\n",
    "print(train_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 52]) torch.Size([64, 52]) torch.Size([64, 1])\n",
      "len(train_dataloader) =  313\n"
     ]
    }
   ],
   "source": [
    "for i, (train, mask, label) in enumerate(train_dataloader): \n",
    "    # torch.Size([16, 128]) torch.Size([16, 128]) torch.Size([16, 1])\n",
    "    print(train.shape, mask.shape, label.shape)\n",
    "    break\n",
    "\n",
    "print('len(train_dataloader) = ', len(train_dataloader))    # 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../huggingface/models/humanized_bert were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ../huggingface/models/humanized_bert and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "#model = num_labels 2 groups\n",
    "num_labels = 2\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"../huggingface/models/humanized_bert\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(52000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\racoon\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr = learning_rate, eps = epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "# training steps : [number of batches] x [number of epochs].\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# ËÆæËÆ° learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(preds, labels): # preds.shape = [16, 2] labels.shape = [16, 1]\n",
    "    correct = torch.eq(torch.max(preds, dim=1)[1], labels.flatten()).float()\n",
    "    acc = correct.sum().item() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round(elapsed))\n",
    "    return str(datetime.timedelta(seconds = elapsed_rounded)) # return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer):\n",
    "    t0 = time.time()\n",
    "    avg_loss, avg_acc = [],[]\n",
    "\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # time print for 40batch .\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids, b_input_mask, b_labels = batch[0].long().to(device), batch[1].long().to(device), batch[2].long().to(device)\n",
    "        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss, logits = output[0], output[1]      # loss:  logits: predict\n",
    "\n",
    "        avg_loss.append(loss.item())\n",
    "\n",
    "        acc = binary_acc(logits, b_labels)       # (predict, label)\n",
    "        avg_acc.append(acc)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 1.0) # \n",
    "        optimizer.step()                         # \n",
    "        scheduler.step()                         # \n",
    "        \n",
    "    avg_acc = np.array(avg_acc).mean()\n",
    "    avg_loss = np.array(avg_loss).mean()\n",
    "    return avg_loss, avg_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    avg_acc = []\n",
    "    model.eval()         # evaluation\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            b_input_ids, b_input_mask, b_labels = batch[0].long().to(device), batch[1].long().to(device), batch[2].long().to(device)\n",
    "\n",
    "            output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "            acc = binary_acc(output[0], b_labels)\n",
    "            avg_acc.append(acc)\n",
    "\n",
    "    avg_acc = np.array(avg_acc).mean()\n",
    "    return avg_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of    313.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:15.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:21.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:27.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:33.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:39.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:45.\n",
      "epoch=0,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.71685303514377ÔºåÊçüÂ§±=0.5700250121351248\n",
      "epoch=0,ÊµãËØïÂáÜÁ°ÆÁéá=0.7496044303797469\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=1,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.7538937699680511ÔºåÊçüÂ§±=0.5101382243937959\n",
      "epoch=1,ÊµãËØïÂáÜÁ°ÆÁéá=0.7551424050632911\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=2,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.7668230830670927ÔºåÊçüÂ§±=0.4896186407381734\n",
      "epoch=2,ÊµãËØïÂáÜÁ°ÆÁéá=0.7652294303797469\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=3,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.7783546325878594ÔºåÊçüÂ§±=0.4726094972973053\n",
      "epoch=3,ÊµãËØïÂáÜÁ°ÆÁéá=0.7676028481012658\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=4,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.7883386581469649ÔºåÊçüÂ§±=0.45727621147426933\n",
      "epoch=4,ÊµãËØïÂáÜÁ°ÆÁéá=0.7846123417721519\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=5,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.794029552715655ÔºåÊçüÂ§±=0.4460349487610899\n",
      "epoch=5,ÊµãËØïÂáÜÁ°ÆÁéá=0.7899525316455697\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=6,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.7997703674121406ÔºåÊçüÂ§±=0.4390627450455492\n",
      "epoch=6,ÊµãËØïÂáÜÁ°ÆÁéá=0.785996835443038\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=7,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8062599840255591ÔºåÊçüÂ§±=0.4286400209219692\n",
      "epoch=7,ÊµãËØïÂáÜÁ°ÆÁéá=0.7950949367088608\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=8,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8075079872204473ÔºåÊçüÂ§±=0.4234604800756747\n",
      "epoch=8,ÊµãËØïÂáÜÁ°ÆÁéá=0.7990506329113924\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=9,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8121006389776357ÔºåÊçüÂ§±=0.4168889936738121\n",
      "epoch=9,ÊµãËØïÂáÜÁ°ÆÁéá=0.794501582278481\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:41.\n",
      "epoch=10,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8125998402555911ÔºåÊçüÂ§±=0.4116726097778771\n",
      "epoch=10,ÊµãËØïÂáÜÁ°ÆÁéá=0.7990506329113924\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=11,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8174920127795527ÔºåÊçüÂ§±=0.40866257059878813\n",
      "epoch=11,ÊµãËØïÂáÜÁ°ÆÁéá=0.8012262658227848\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=12,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8168430511182109ÔºåÊçüÂ§±=0.40509255877889383\n",
      "epoch=12,ÊµãËØïÂáÜÁ°ÆÁéá=0.783623417721519\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=13,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8197883386581469ÔºåÊçüÂ§±=0.3980410312311337\n",
      "epoch=13,ÊµãËØïÂáÜÁ°ÆÁéá=0.7941060126582279\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=14,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8208366613418531ÔºåÊçüÂ§±=0.3941653589375865\n",
      "epoch=14,ÊµãËØïÂáÜÁ°ÆÁéá=0.7964794303797469\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=15,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8241313897763578ÔºåÊçüÂ§±=0.3889033896759295\n",
      "epoch=15,ÊµãËØïÂáÜÁ°ÆÁéá=0.7958860759493671\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=16,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8257288338658147ÔºåÊçüÂ§±=0.38684013928658667\n",
      "epoch=16,ÊµãËØïÂáÜÁ°ÆÁéá=0.7988528481012658\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=17,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.83002196485623ÔºåÊçüÂ§±=0.38057617486094514\n",
      "epoch=17,ÊµãËØïÂáÜÁ°ÆÁéá=0.7998417721518988\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=18,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8287739616613419ÔºåÊçüÂ§±=0.3773179184704924\n",
      "epoch=18,ÊµãËØïÂáÜÁ°ÆÁéá=0.8008306962025317\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=19,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8303214856230032ÔºåÊçüÂ§±=0.37568994171131914\n",
      "epoch=19,ÊµãËØïÂáÜÁ°ÆÁéá=0.7962816455696202\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=20,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8323182907348243ÔºåÊçüÂ§±=0.37232655639084766\n",
      "epoch=20,ÊµãËØïÂáÜÁ°ÆÁéá=0.7966772151898734\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=21,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8318690095846646ÔºåÊçüÂ§±=0.37058597941177723\n",
      "epoch=21,ÊµãËØïÂáÜÁ°ÆÁéá=0.7996439873417721\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=22,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8358126996805112ÔºåÊçüÂ§±=0.364709801805286\n",
      "epoch=22,ÊµãËØïÂáÜÁ°ÆÁéá=0.7937104430379747\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=23,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8339157348242812ÔºåÊçüÂ§±=0.36331416956913737\n",
      "epoch=23,ÊµãËØïÂáÜÁ°ÆÁéá=0.8004351265822784\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=24,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.838158945686901ÔºåÊçüÂ§±=0.357806208748787\n",
      "epoch=24,ÊµãËØïÂáÜÁ°ÆÁéá=0.7950949367088608\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=25,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8399061501597445ÔºåÊçüÂ§±=0.35834524363945847\n",
      "epoch=25,ÊµãËØïÂáÜÁ°ÆÁéá=0.789754746835443\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=26,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8384085463258786ÔºåÊçüÂ§±=0.35472676157951355\n",
      "epoch=26,ÊµãËØïÂáÜÁ°ÆÁéá=0.7937104430379747\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=27,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8426018370607029ÔºåÊçüÂ§±=0.3511617801155145\n",
      "epoch=27,ÊµãËØïÂáÜÁ°ÆÁéá=0.7960838607594937\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=28,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8393071086261981ÔºåÊçüÂ§±=0.3518971347104246\n",
      "epoch=28,ÊµãËØïÂáÜÁ°ÆÁéá=0.7925237341772152\n",
      "  Batch    40  of    313.    Elapsed: 0:00:06.\n",
      "  Batch    80  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   120  of    313.    Elapsed: 0:00:18.\n",
      "  Batch   160  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:30.\n",
      "  Batch   240  of    313.    Elapsed: 0:00:36.\n",
      "  Batch   280  of    313.    Elapsed: 0:00:42.\n",
      "epoch=29,ËÆ≠ÁªÉÂáÜÁ°ÆÁéá=0.8433007188498403ÔºåÊçüÂ§±=0.34841931832674594\n",
      "epoch=29,ÊµãËØïÂáÜÁ°ÆÁéá=0.7952927215189873\n"
     ]
    }
   ],
   "source": [
    "train_loss_histoty = []\n",
    "train_acc_history = []\n",
    "test_acc_history = []\n",
    "epoch_history = []\n",
    "for epoch in range(epochs):  \n",
    "    train_loss, train_acc = train(model, optimizer)\n",
    "    train_loss_histoty.append(train_loss)\n",
    "    train_acc_history.append(train_acc)\n",
    "    epoch_history.append(epoch)\n",
    "    print('epoch={},ËÆ≠ÁªÉÂáÜÁ°ÆÁéá={}ÔºåÊçüÂ§±={}'.format(epoch, train_acc, train_loss))\n",
    "    test_acc = evaluate(model)\n",
    "    test_acc_history.append(test_acc)\n",
    "    print(\"epoch={},ÊµãËØïÂáÜÁ°ÆÁéá={}\".format(epoch, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    " \n",
    "#loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist['epoch'] = epoch_history\n",
    "hist['train_acc'] = train_acc_history\n",
    "hist['train_loss'] = train_loss_histoty\n",
    "hist['test_acc'] = test_acc_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Train')\n",
    "    plt.plot(hist['epoch'], hist['train_acc'],\n",
    "           label='Train Accuracy')\n",
    "    plt.plot(hist['epoch'], hist['train_loss'],\n",
    "           label = 'Train Loss')\n",
    "    plt.plot(hist['epoch'], hist['test_acc'],\n",
    "           label = 'Test Accuracy')\n",
    "    plt.ylim([0,1])\n",
    "    plt.legend()\n",
    "    plt.savefig('../huggingface/visual_result/AAV2_single_mutant_nab_Bert_aav_30epoch.png',dpi=300)#save result\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3 external evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    \"aav2bert-finetuning\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions[:, 0]\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizerÔºå\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "01_how-to-train.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python_pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "016d7c8318f742c1943464b08232a510": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04e7e6d291da49d5816dc98a2904e95c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39c23c6a972b419eb2eeeebafeaedc22",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8388e9da9da4492c98c19235ca5fc1b5",
      "value": " 15228/15228 [2:46:46&lt;00:00,  1.52it/s]"
     }
    },
    "0989d41a4da24e9ebff377e02127642c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d295dd80550447d88da0f04ce36a22ff",
       "IPY_MODEL_04e7e6d291da49d5816dc98a2904e95c"
      ],
      "layout": "IPY_MODEL_42c6061ef7e44f179db5a6e3551c0f17"
     }
    },
    "39c23c6a972b419eb2eeeebafeaedc22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40bf955ba0284e84b198da6be8654219": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "42c6061ef7e44f179db5a6e3551c0f17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6feb10aeb43147e6aba028d065947ae8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "837c9ddc3d594e088891874560c646b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Epoch: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe20a8dae6e84628b5076d02183090f5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40bf955ba0284e84b198da6be8654219",
      "value": 1
     }
    },
    "8388e9da9da4492c98c19235ca5fc1b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93b3f9eae3cb4e3e859cf456e3547c6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a491e8caa0a048beb3b5259f14eb233f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a58a66392b644b1384661e850c077a6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_837c9ddc3d594e088891874560c646b8",
       "IPY_MODEL_dbf50873d62c4ba39321faefbed0cca5"
      ],
      "layout": "IPY_MODEL_a491e8caa0a048beb3b5259f14eb233f"
     }
    },
    "d295dd80550447d88da0f04ce36a22ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Iteration: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_016d7c8318f742c1943464b08232a510",
      "max": 15228,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7d8c3a4fecd40778e32966b29ea65a1",
      "value": 15228
     }
    },
    "dbf50873d62c4ba39321faefbed0cca5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6feb10aeb43147e6aba028d065947ae8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_93b3f9eae3cb4e3e859cf456e3547c6d",
      "value": " 1/1 [2:46:46&lt;00:00, 10006.17s/it]"
     }
    },
    "e7d8c3a4fecd40778e32966b29ea65a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fe20a8dae6e84628b5076d02183090f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
